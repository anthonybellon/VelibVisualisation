{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374d2806-66e6-48e3-83b9-e6b536e1d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../scripts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d102f858-389f-4a20-acac-a6119339896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import data_preprocessing\n",
    "import train_model\n",
    "import predict_and_compare\n",
    "import utils\n",
    "\n",
    "def test_workflow():\n",
    "    # 1. Preprocess Data\n",
    "    data_preprocessing.preprocess_data()\n",
    "\n",
    "    # 2. Train Model\n",
    "    processed_data_path = os.path.abspath('../data/processed_bike_data.parquet')\n",
    "    bike_data = pd.read_parquet(processed_data_path)\n",
    "    stations = bike_data['stationcode'].unique()[:5]  # Use a subset for testing\n",
    "    models, scaler, nearby_station_results = train_model.train_model(bike_data, stations)\n",
    "\n",
    "    # Save and reload models and scalers for consistency\n",
    "    model_file_path = os.path.abspath('../data/test_model.pkl')\n",
    "    scaler_file_path = os.path.abspath('../data/test_scaler.pkl')\n",
    "    with open(model_file_path, 'wb') as f:\n",
    "        pickle.dump(models, f)\n",
    "    with open(scaler_file_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "    with open(model_file_path, 'rb') as f:\n",
    "        loaded_models = pickle.load(f)\n",
    "    with open(scaler_file_path, 'rb') as f:\n",
    "        loaded_scaler = pickle.load(f)\n",
    "\n",
    "    # 3. Predict and Compare\n",
    "    data_file_path = os.path.abspath('../data/use_for_predictions.json')\n",
    "    with open(data_file_path, 'r') as f:\n",
    "        current_data = json.load(f)\n",
    "    current_bike_data = predict_and_compare.preprocess_current_data(current_data)\n",
    "    current_bike_data = predict_and_compare.calculate_nearby_station_status(current_bike_data, limit=5)\n",
    "    \n",
    "    # Load feature names used during training\n",
    "    with open('../data/training_feature_names.json', 'r') as f:\n",
    "        feature_names = json.load(f)\n",
    "    \n",
    "    current_bike_data = predict_and_compare.normalize_features(current_bike_data, feature_names, loaded_scaler)\n",
    "    results_df = predict_and_compare.make_predictions(current_bike_data, loaded_models, feature_names)\n",
    "    predict_and_compare.save_results(results_df, current_bike_data)\n",
    "\n",
    "    print(\"Test workflow completed successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86750270-28c7-4ec5-b63e-2258e2e1bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned bike data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading JSON files: 100%|█████████████████████████████████████████████████████████████████████████| 7/7 [01:19<00:00, 11.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing bike data...\n",
      "Extracting latitude and longitude...\n",
      "Stations with duplicate coordinates found:\n",
      "Empty DataFrame\n",
      "Columns: [stationcode, name, is_installed, capacity, numdocksavailable, numbikesavailable, mechanical, ebike, is_renting, is_returning, duedate, coordonnees_geo, nom_arrondissement_communes, date, lat, lon]\n",
      "Index: []\n",
      "Duplicate coordinate groups:\n",
      "Empty DataFrame\n",
      "Columns: [lat, lon, count]\n",
      "Index: []\n",
      "Duplicate coordinates data saved to /Users/anthonybellon/Comp_Documents/VelibVisualisation/data/duplicate_coordinates.json\n",
      "Removing NaN values...\n",
      "Creating features...\n",
      "Feature names saved to /Users/anthonybellon/Comp_Documents/VelibVisualisation/data/feature_names.json\n",
      "Data saved to /Users/anthonybellon/Comp_Documents/VelibVisualisation/data/processed_bike_data.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:06:19,846 - INFO - Training models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:   0%|                                                                               | 0/5 [00:00<?, ?station/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid indices for station 10001: [1019, 7, 6, 1005, 1, 0, 1006, 10, 1004, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:07:02,319 - INFO - Cross-Validation Score for station 10001: -0.0031164632755577874\n",
      "2024-06-09 21:07:02,578 - INFO - Mean Squared Error for station 10001: 0.0006502646279965751\n",
      "Training models:  20%|██████████████▏                                                        | 1/5 [00:12<00:51, 12.97s/station]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid indices for station 10001_relais: [1019, 7, 6, 1005, 1, 0, 10, 1004, 9, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:07:59,721 - INFO - Cross-Validation Score for station 10001_relais: -6.863696860913937e-07\n",
      "2024-06-09 21:08:02,225 - INFO - Mean Squared Error for station 10001_relais: 9.791210155841647e-09\n",
      "Training models:  40%|████████████████████████████▍                                          | 2/5 [01:12<02:01, 40.43s/station]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid indices for station 10003: [716, 759, 764, 798, 1444, 40, 4, 758, 44, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:09:00,943 - INFO - Cross-Validation Score for station 10003: -5.782926033007414e-06\n",
      "2024-06-09 21:09:04,588 - INFO - Mean Squared Error for station 10003: 2.1919276035797052e-07\n",
      "Training models:  60%|██████████████████████████████████████████▌                            | 3/5 [02:14<01:40, 50.44s/station]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid indices for station 10004: [1012, 1019, 63, 758, 44, 2, 3, 7, 5, 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:10:06,128 - INFO - Cross-Validation Score for station 10004: -8.935428421769649e-06\n",
      "2024-06-09 21:10:08,699 - INFO - Mean Squared Error for station 10004: 1.128944890171254e-05\n",
      "Training models:  80%|████████████████████████████████████████████████████████▊              | 4/5 [03:19<00:55, 55.84s/station]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of bounds indices for station 10005: [1474]\n",
      "Max valid index: 1460\n",
      "Valid indices for station 10005: [764, 1444, 40, 1443, 4, 1441, 1434, 2, 19, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:11:00,109 - INFO - Cross-Validation Score for station 10005: -1.0852655380635226e-05\n",
      "2024-06-09 21:11:02,720 - INFO - Mean Squared Error for station 10005: 1.1752241334299238e-09\n",
      "Training models: 100%|███████████████████████████████████████████████████████████████████████| 5/5 [04:13<00:00, 50.62s/station]\n",
      "/Users/anthonybellon/Comp_Documents/VelibVisualisation/scripts/predict_and_compare.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  current_bike_data.fillna(0, inplace=True)\n",
      "Calculating nearby station status:  60%|██████████████████████████████████▊                       | 3/5 [00:05<00:03,  1.94s/it]"
     ]
    }
   ],
   "source": [
    "test_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd419aa6-a6fa-4d73-a36e-b1b55cff61be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
